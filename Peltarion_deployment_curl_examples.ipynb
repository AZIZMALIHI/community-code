{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "from requests_toolbelt import MultipartEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows some examples of how to call a model trained and deployed in the Peltarion platform from Python using requests with forms, mimicking a curl call.\n",
    "\n",
    "The disadvantage of using this method is that you can only score one example at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification\n",
    "\n",
    "We will hide the deployment URL and the authentication token for security reasons. You can substitute the values found on the Deployment page for the model we want to use.\n",
    "\n",
    "The following example assumes that you have a model trained on MNIST data (28x28 pixels, 3 color channels) and want to classify new images that the model has not seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ' -- insert the URL you find on the deployment page -- '\n",
    "token = ' -- insert the token you find on the deployment page --'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to classify an image in file called `three.png` can be found in the `images` folder of this repo. The name of the only feature that this model uses is \"Image\". You will find the name of the feature(s) on the deployment page for your model.\n",
    "\n",
    "Here the cURL call (which you can find a skeleton for on the deployment page) would look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "curl -X POST -F \"Image=@images/three.png\" \\\n",
    "-u \" -- token from deployment page -- :\" \\\n",
    "\" -- URL from deployment page --\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the \":\" that has to be present after the token. You can run curl from the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Number\":{\"0\":1.1728967E-12,\"1\":1.904032E-23,\"2\":1.0426308E-9,\"3\":0.99999976,\"4\":8.7458367E-32,\"5\":2.2160066E-7,\"6\":1.1102806E-25,\"7\":8.750066E-19,\"8\":9.540412E-19,\"9\":6.100854E-9}}"
     ]
    }
   ],
   "source": [
    "!curl -X POST -F \"Image=@images/three.png\" \\\n",
    "-u \"-- insert your token -- :\" \\\n",
    "\"-- insert your URL --\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now let's do the same thing in Python. We start by defining a small function to get a prediction. The input_dict will be a dictionary containing information about your inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(input_dict, token, url):\n",
    "    payload = MultipartEncoder(input_dict)\n",
    "    r = requests.post(url,\n",
    "                      data=payload,\n",
    "                      headers={'Content-Type': payload.content_type},\n",
    "                      auth=(token, ''))\n",
    "    return(eval(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a dictionary containing the name and file path of the image we want to classify. The name is again the feature name we see on the Deployment page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image, path = 'Image', 'images/three.png'\n",
    "input_dict = {image: (path, open(path, 'rb'), 'image/png')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the function defined above by inserting the input_dict, the token and the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number': {'0': 1.1728967e-12,\n",
       "  '1': 1.904032e-23,\n",
       "  '2': 1.0426308e-09,\n",
       "  '3': 0.99999976,\n",
       "  '4': 8.7458367e-32,\n",
       "  '5': 2.2160066e-07,\n",
       "  '6': 1.1102806e-25,\n",
       "  '7': 8.750066e-19,\n",
       "  '8': 9.540412e-19,\n",
       "  '9': 6.100854e-09}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = get_prediction(input_dict, token, url)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying several images\n",
    "\n",
    "For classifying a batch of examples, it is better to use JSON requests (see the Peltarion_deployment_JSON_examples.ipynb notebook in this repo). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using multiple inputs\n",
    "\n",
    "Here we are using the California housing dataset together with images from Google maps, so that we have a set of numerical inputs as well as an image input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ' -- insert the URL you find on the deployment page -- '\n",
    "token = ' -- insert the token you find on the deployment page --'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the numerical inputs, we just write key-value pairs consisting of the feature names from the deployment page and their corresponding values. For the image input, we add it to the dictionary as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'images/15_5256_12656.png'\n",
    "img_dict = {'image_path': (img_path, open(img_path, 'rb'), 'image/png')}\n",
    "num_dict =  {\n",
    "    \"population\": \"1551.0\",\n",
    "    \"totalBedrooms\": \"434.0\",\n",
    "    \"totalRooms\": \"2202.0\",\n",
    "    \"housingMedianAge\": \"52.0\",\n",
    "    \"medianIncome\": \"3.12\",\n",
    "    \"households\": \"514.0\",\n",
    "    \"latitude\": \"37.88\",\n",
    "    \"longitude\": \"-122.25\"\n",
    "}\n",
    "\n",
    "input_dict = {**img_dict, **num_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': ('images/15_5256_12656.png',\n",
       "  <_io.BufferedReader name='images/15_5256_12656.png'>,\n",
       "  'image/png'),\n",
       " 'population': '1551.0',\n",
       " 'totalBedrooms': '434.0',\n",
       " 'totalRooms': '2202.0',\n",
       " 'housingMedianAge': '52.0',\n",
       " 'medianIncome': '3.12',\n",
       " 'households': '514.0',\n",
       " 'latitude': '37.88',\n",
       " 'longitude': '-122.25'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'medianHouseValue': 204714.05}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(input_dict, token, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will send two images to a deployment and get two images back. The images come from the NoisyOffice dataset (https://archive.ics.uci.edu/ml/datasets/NoisyOffice) where the task is to clean images from stains and other imperfections.\n",
    "\n",
    "The sole input feature is called `path_noisy` and the output is called `path_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ' -- insert the URL you find on the deployment page -- '\n",
    "token = ' -- insert the token you find on the deployment page --'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, path = 'path_noisy', 'images/FontLrm_Noisec_TE.png'\n",
    "input_dict = {image: (path, open(path, 'rb'), 'image/png')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will be returned as a base64 encoded string, which you can for example save to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_prediction(input_dict, token, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = base64.b64decode(output['path_clean'].split(',')[-1])\n",
    "with open('images/reconstructed_image.png', 'bw') as outf:\n",
    "    outf.write(decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
