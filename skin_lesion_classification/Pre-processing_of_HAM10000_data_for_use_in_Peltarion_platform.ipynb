{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of HAM10000 data for use in Peltarion platform\n",
    "\n",
    "This notebook guides you through the process of downloading and preparing the HAM10000 data set for use in the Peltarion platform.\n",
    "\n",
    "## Downloading the data set\n",
    "Before running this notebook you need to download the HAM10000 images and their corresponding metadata from this [ISIC webpage](https://www.isic-archive.com/#!/topWithHeader/onlyHeaderTop/gallery). Under __DATABASE ATTRIBUTES__ select __DATASET: HAM10000__. At the top of the page you should now see __Filtered images: 10015__. At the top right of the page click __Download as zip__ and select __Download Images and Metadata__. The downloaded zip file contains 10015 jpg images and a metadata.csv file with information about each of the images. Unzip the file into a local folder on your computer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "np.random.seed(1) # Set seed explicitly to get determinstic training/validation data split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "### Configure paths\n",
    "\n",
    "Modify the __metadata_path__ and __image_path__ to correspond with where you unzipped the downloaded file.\n",
    "Specify the __out_path__ to where the output data from this notebook should be written. The directory should not exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"/home/asa/demo/ISIC-images/metadata.csv\"\n",
    "image_path =  \"/home/asa/demo/ISIC-images/HAM10000\"\n",
    "out_path = \"/home/asa/demo/workshop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/asa/demo/workshop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-876630e8f049>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/asa/demo/workshop'"
     ]
    }
   ],
   "source": [
    "os.mkdir(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify options for the pre-processing\n",
    "__TRAINING_PERCENT__  \n",
    "Percentage of the images that should be used for training (the rest will be used for validation)\n",
    "\n",
    "__IMAGE_SIZE__  \n",
    "(width, height) Output image size after resizing of all images. The original HAM10000 images are 600x450 which is quite big. In order to fit a reasonably sized batch (16-64 images) of your model in gpu memory you can choose to resize them to smaller dimensions, for example 200x150, before importing to Peltarion platform. \n",
    "\n",
    "__BALANCE_CLASSES__  \n",
    "True or False. The classes in this dataset are very imbalanced. Usually better model performance can be achieved by training with balanced classes. To create a dataset where all 7 classes are equally balanced put this parameter to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PERCENT = 80\n",
    "IMAGE_SIZE = (60,45)\n",
    "BALANCE_CLASSES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and clean up metadata\n",
    "\n",
    "Select only a few of the columns that we will use, shorten column names and replace NaNs with the string \"unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_path)\n",
    "cols = [\"name\", \n",
    "        \"meta.clinical.age_approx\", \n",
    "        \"meta.clinical.benign_malignant\",\n",
    "        \"meta.clinical.diagnosis\",\n",
    "        \"meta.clinical.diagnosis_confirm_type\",\n",
    "        \"meta.clinical.sex\", \n",
    "        ]\n",
    "cols_renamed = {\"name\": \"image\",\n",
    "                \"meta.clinical.age_approx\": \"age\",\n",
    "                \"meta.clinical.benign_malignant\": \"benign_malignant\",\n",
    "                \"meta.clinical.diagnosis\": \"diagnosis\",\n",
    "                \"meta.clinical.diagnosis_confirm_type\": \"diagnosis_confirm_type\",\n",
    "                \"meta.clinical.sex\": \"sex\"\n",
    "               }\n",
    "metadata = metadata[cols]\n",
    "metadata = metadata.rename(index=str, columns=cols_renamed)\n",
    "metadata['image'] = metadata[\"image\"]+\".jpg\"\n",
    "metadata[\"age\"] = metadata[\"age\"].fillna(0)\n",
    "metadata = metadata.fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata.groupby(\"benign_malignant\").count()[[\"image\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.groupby(\"diagnosis\").count()[[\"image\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata.groupby([\"diagnosis\", \"benign_malignant\"]).count()[[\"image\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize images and write to out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_samples = metadata.shape[0]\n",
    "print (\"Starting the processing of \" + str(num_samples) + \" images. This can take a few minutes.\")\n",
    "for idx, row in metadata.iterrows():\n",
    "    if int(idx) % 1000 == 0:\n",
    "        print (idx +\" samples out of \" + str(num_samples) + \" samples processed\")\n",
    "    img_name = row[\"image\"]\n",
    "    im = Image.open(os.path.join(image_path, img_name))\n",
    "    im = im.resize(IMAGE_SIZE)\n",
    "    im.save(os.path.join(out_path, img_name))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train/val data according to TRAINING_PERCENT parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['subset'] = np.where(np.random.randint(0, 100, metadata.shape[0]) <= TRAINING_PERCENT, 'train', 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata.groupby([\"subset\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform class balancing\n",
    "\n",
    "This performs class balancing over the 7 classes by duplicating/oversampling the rarer classes.\n",
    "Note that the oversampling is only done on the training data set, not for validation data.\n",
    "True class distribution is kept for the validation data in order to get proper performance metrics on the validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata.groupby([\"subset\",\"diagnosis\"]).count()[[\"image\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BALANCE_CLASSES:\n",
    "    max_size = metadata[metadata['subset']=='train']['diagnosis'].value_counts().max()\n",
    "    lst = [metadata]\n",
    "    for class_index, group in metadata[metadata['subset']=='train'].groupby('diagnosis'):\n",
    "        lst.append(group.sample(max_size-len(group), replace=True))\n",
    "    metadata = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.groupby([\"subset\",\"diagnosis\"]).count()[[\"image\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write metadata to index.csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.to_csv(os.path.join(out_path, \"index.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the zip file that can be uploaded to the platform\n",
    "\n",
    "This final step you perform outside of this notebook. \n",
    "You have to bundle the produced index.csv file and the resized images into a single zip file. \n",
    "You can do this in a terminal window by navigating to the __out_path__ that you specified above, and running below command:\n",
    "\n",
    "zip mybundle.zip -r ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
