{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows some examples of how to call a model trained and deployed in the Peltarion platform from Python using JSON requests.\n",
    "\n",
    "The advantage of using JSON is that you can score several examples in a batch rather than one at a time as with curl or POST requests with forms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification\n",
    "\n",
    "### Classify a single image\n",
    "\n",
    "The following example assumes that you have a model trained on [MNIST](http://docs.peltarion.com/new/en/datasets-view/datasets-used-in-tutorials/mnist-dataset.html) data (28x28 pixels, 3 color channels) and want to classify new images that the model has not seen. Pretty much the same thing what you do in the tutorial [Deploy an operational AI model](http://docs.peltarion.com/new/en/tutorials/tutorial---deploy-an-operational-ai-model.html).\n",
    "\n",
    "We will hide the deployment URL and the authentication token for security reasons. You can substitute the values found on the Deployment view for the model we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ' -- insert the URL you find on the deployment view -- '\n",
    "token = ' -- insert the token you find on the deployment view --'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file called `three.png` can be found in the images folder of this repo.\n",
    "\n",
    "In order to feed the image to the deployment API, we need to encode it in base64 format and prepend a short string explaining what type of data it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = \"images/three.png\"\n",
    "img_type = os.path.splitext(img_file)[-1][1:]\n",
    "with open(img_file, \"rb\") as image_file:\n",
    "    encoded_img = 'data:image/{};base64,'.format(img_type) + base64.b64encode(image_file.read()).decode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the JSON string that we will send is shown below. The \"rows\" key must always be present and its value is a list of strings that represent different examples that we want to classify. Each entry of the list contains a comma-separated set of key-value pairs where the key is the feature name and the value is the feature value (which will be a base64 string for images.)\n",
    "\n",
    "```\n",
    "  {\"rows\": \n",
    "  \t[{\"feature1\": \"value1\", \"feature2\": \"value2\"}, \n",
    "  \t {\"feature1\": \"value1\", \"feature2\": \"value2\"}\n",
    "  \t]\n",
    "  }\n",
    "```\n",
    "For the current example, we only have one example and one feature called \"Image\". (You can find the feature names on the Deployment view.) The structure of the JSON will be fairly simple:\n",
    "\n",
    "```\n",
    "  {\"rows\": \n",
    "  \t[{\"Image\": \"<base64 encoded image>\"}]\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rows': [{'Number': {'0': 1.172899e-12, '1': 1.904032e-23, '2': 1.0426288e-09, '3': 0.99999976, '4': 8.7458367e-32, '5': 2.2160087e-07, '6': 1.1102806e-25, '7': 8.750066e-19, '8': 9.540449e-19, '9': 6.100877e-09}}]}\n"
     ]
    }
   ],
   "source": [
    "payload = \"{\\\"rows\\\": [{\\\"Image\\\":\\\"\" + encoded_img + \"\\\"}]}\"\n",
    "headers = {\n",
    "    'Content-Type': \"application/json\",\n",
    "    'Authorization': \"Bearer {}\".format(token),\n",
    "    }\n",
    "\n",
    "response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: ‘3’ gets the highest value, 0.99999976. This means that the model predicts the image to be a ‘3’. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify several images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify our life, we might want to write a small function that encodes an image to base64 given a file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_img(path):\n",
    "    img_type = os.path.splitext(path)[-1][1:]\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        encoded_img = 'data:image/{};base64,'.format(img_type) + base64.b64encode(image_file.read()).decode('ascii')\n",
    "    return encoded_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can classify a batch of images, in this case just two, but it would work with a much larger batch too. The files can be found in the images folder of this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = ['images/three.png', 'images/Six.png']\n",
    "encoded_imgs = [encode_img(f) for f in img_files]\n",
    "input_batch = ','.join([\"{\\\"Image\\\":\\\"\" + encoded_img + \"\\\"}\" for encoded_img in encoded_imgs])\n",
    "payload = \"{\\\"rows\\\": [\" + input_batch + \"]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rows': [{'Number': {'0': 1.1729013e-12,\n",
       "    '1': 1.904032e-23,\n",
       "    '2': 1.0426308e-09,\n",
       "    '3': 0.99999976,\n",
       "    '4': 8.7458367e-32,\n",
       "    '5': 2.2160044e-07,\n",
       "    '6': 1.1102806e-25,\n",
       "    '7': 8.750066e-19,\n",
       "    '8': 9.540412e-19,\n",
       "    '9': 6.100854e-09}},\n",
       "  {'Number': {'0': 9.634732e-05,\n",
       "    '1': 8.909446e-09,\n",
       "    '2': 3.8414715e-08,\n",
       "    '3': 1.0719662e-05,\n",
       "    '4': 7.3074455e-07,\n",
       "    '5': 0.0041560247,\n",
       "    '6': 0.9956968,\n",
       "    '7': 8.453612e-08,\n",
       "    '8': 1.8743322e-05,\n",
       "    '9': 2.0451373e-05}}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: The first image is predicted to be a '3' and the second to a '6'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular data \n",
    "\n",
    "This example assumes that we have trained a model on the California housing dataset, where we try to predict latitude from some numeric features.\n",
    "In this example we try to predict on which latitude a house is situated. We assume that the deployed model has been trained on the [Calihouse dataset](http://docs.peltarion.com/new/en/datasets-view/datasets-used-in-tutorials/calihouse-dataset.html) as in the tutorial [Predict California house prices](http://docs.peltarion.com/new/en/tutorials/tutorial---predict-california-house-prices.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ' -- insert the URL you find on the deployment view -- '\n",
    "token = ' -- insert the token you find on the deployment view --'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a short utility function to construct a row for a training example in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_row(input_params):\n",
    "    return '{' + ','.join([\"\\\"\" + name + \"\\\":\" + value for (name, value) in input_params.items()]) + '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = {\n",
    "\"population\": \"1551.0\",\n",
    "\"totalBedrooms\": \"434.0\",\n",
    "\"totalRooms\": \"2202.0\",\n",
    "\"housingMedianAge\": \"52.0\",\n",
    "\"medianHouseValue\": \"261100.0\",\n",
    "\"medianIncome\": \"3.12\",\n",
    "\"households\": \"514.0\"\n",
    "}\n",
    "\n",
    "ex2 = {\n",
    "\"population\": \"3551.0\",\n",
    "\"totalBedrooms\": \"834.0\",\n",
    "\"totalRooms\": \"2902.0\",\n",
    "\"housingMedianAge\": \"76.0\",\n",
    "\"medianHouseValue\": \"111100.0\",\n",
    "\"medianIncome\": \"2.12\",\n",
    "\"households\": \"1000.0\"\n",
    "}\n",
    "\n",
    "examples = [ex1, ex2]\n",
    "input_batch = ','.join([input_row(ex) for ex in examples])\n",
    "payload = \"{\\\"rows\\\": [\" + input_batch + \"]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"rows\": [{\"population\":1551.0,\"totalBedrooms\":434.0,\"totalRooms\":2202.0,\"housingMedianAge\":52.0,\"medianHouseValue\":261100.0,\"medianIncome\":3.12,\"households\":514.0},{\"population\":3551.0,\"totalBedrooms\":834.0,\"totalRooms\":2902.0,\"housingMedianAge\":76.0,\"medianHouseValue\":111100.0,\"medianIncome\":2.12,\"households\":1000.0}]}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rows': [{'latitude': 37.7944}, {'latitude': 37.922215}]}\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'Content-Type': \"application/json\",\n",
    "    'Authorization': \"Bearer {}\".format(token),\n",
    "    }\n",
    "\n",
    "response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: The model predicts that the second house is situated slightly north of the first house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images and tabular data\n",
    "\n",
    "In this example, we will predict the mean house value in a specific area, just as in the tutorial [Predict California house prices](http://docs.peltarion.com/new/en/tutorials/tutorial---predict-california-house-prices.html). We use a model trained on the [Calihouse dataset](http://docs.peltarion.com/new/en/datasets-view/datasets-used-in-tutorials/calihouse-dataset.html) that consists of map images from [Open street map](https://www.openstreetmap.org/about) and tabular demographic data collected from the California 1990 Census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ' -- insert the URL you find on the Deployment view -- '\n",
    "token = ' -- insert the token you find on the Deployment view --'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will re-use the `encode_imgs()` function defined above here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = ['images/15_5256_12656.png', 'images/15_5258_12653.png']\n",
    "encoded_imgs = [encode_img(f) for f in img_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now populate the examples with numerical values and encoded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rows': [{'medianHouseValue': 204714.05}, {'medianHouseValue': 298926.44}]}\n"
     ]
    }
   ],
   "source": [
    "ex1 = {\n",
    "\"population\": \"1551.0\",\n",
    "\"totalBedrooms\": \"434.0\",\n",
    "\"totalRooms\": \"2202.0\",\n",
    "\"housingMedianAge\": \"52.0\",\n",
    "\"medianIncome\": \"3.12\",\n",
    "\"households\": \"514.0\",\n",
    "\"image_path\": \"\\\"\" + encoded_imgs[0] + \"\\\"\",\n",
    "\"latitude\": \"37.88\",\n",
    "\"longitude\": \"-122.25\"\n",
    "}\n",
    "\n",
    "ex2 = {\n",
    "\"population\": \"3551.0\",\n",
    "\"totalBedrooms\": \"834.0\",\n",
    "\"totalRooms\": \"2902.0\",\n",
    "\"housingMedianAge\": \"76.0\",\n",
    "\"medianIncome\": \"2.12\",\n",
    "\"households\": \"1000.0\",\n",
    "\"image_path\": \"\\\"\" + encoded_imgs[1] + \"\\\"\",\n",
    "\"latitude\": \"37.88\",\n",
    "\"longitude\": \"-122.25\"\n",
    "}\n",
    "\n",
    "examples = [ex1,ex2]\n",
    "input_batch = ','.join([input_row(ex) for ex in examples])\n",
    "payload = \"{\\\"rows\\\": [\" + input_batch + \"]}\"\n",
    "headers = {\n",
    "    'Content-Type': \"application/json\",\n",
    "    'Authorization': \"Bearer {}\".format(token),\n",
    "    }\n",
    "\n",
    "response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: The model predicts that the area where the second house is situated is more expensive than the first houses' area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image to image\n",
    "\n",
    "Here we will send two images to a deployment and get two images back. This is useful for image-to-image mapping problems, such as image segmentation or image denoising/reconstruction.\n",
    "The images in this example come from the [NoisyOffice dataset](https://archive.ics.uci.edu/ml/datasets/NoisyOffice) where the task is to clean images from stains and other imperfections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ' -- insert the URL you find on the Deployment view -- '\n",
    "token = ' -- insert the token you find on the Deployment view --'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = ['images/FontLrm_Noisec_TE.png', 'images/FontLrm_Noisew_TE.png']\n",
    "encoded_imgs = [encode_img(f) for f in img_files]\n",
    "input_batch = ','.join([\"{\\\"path_noisy\\\":\\\"\" + encoded_img + \"\\\"}\" for encoded_img in encoded_imgs])\n",
    "payload = \"{\\\"rows\\\": [\" + input_batch + \"]}\"\n",
    "headers = {\n",
    "    'Content-Type': \"application/json\",\n",
    "    'Authorization': \"Bearer {}\".format(token),\n",
    "    }\n",
    "\n",
    "response = requests.request(\"POST\", url, data=payload, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = response.json()['rows']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can, for example, save the generated images to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, res in enumerate(results):\n",
    "    decoded = base64.b64decode(res['path_clean'].split(',')[-1])\n",
    "    with open('images/image{}.png'.format(i), 'bw') as outf:\n",
    "        outf.write(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy to numpy\n",
    "\n",
    "Here we will send input data represented as numpy arrays to the deployment API, and get a numpy array of predictions back. \n",
    "\n",
    "The numpy data type can be used to build several models, e.g. auto-encoders, segmentation models, or multi-label classification of vectors or images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from deployment api \n",
    "# Return the response as json\n",
    "def get_predictions(data, token, url):\n",
    "    headers = {\n",
    "    'Content-Type': \"application/json\",\n",
    "    'Authorization': \"Bearer {}\".format(token),\n",
    "    }\n",
    "    response = requests.request(\"POST\", url, data=data, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# Prepare a json data structure from numpy array\n",
    "# Assume first axis in the numpy array arr represents samples\n",
    "def prepare_api_data(arr, input_param_name=\"input\"):\n",
    "    encoded_arrs = [encode_numpy(a) for a in arr]\n",
    "    input_batch = ','.join([\"{\\\"\" + input_param_name + \"\\\":\\\"\" + encoded_arr + \"\\\"}\" for encoded_arr in encoded_arrs])\n",
    "    payload = \"{\\\"rows\\\": [\" + input_batch + \"]}\"\n",
    "    return payload\n",
    "\n",
    "# Encode a numpy array in base64 format and add data application type\n",
    "def encode_numpy(arr):\n",
    "    # Need to temp save the arr to a buffer to get the npy headers not just the raw data\n",
    "    buffer = io.BytesIO()\n",
    "    np.save(buffer, arr)\n",
    "    encoded_arr = base64.b64encode(buffer.getvalue()).decode('ascii')\n",
    "    return 'data:application/x.peltarion.npy;base64,' + encoded_arr\n",
    "    \n",
    "# Decode a base64 string into a numpy array\n",
    "def decode_base64(base64_string):\n",
    "    decoded = base64.decodebytes(base64_string.encode('ascii'))\n",
    "    buffer = io.BytesIO(decoded)\n",
    "    return np.load(buffer)\n",
    "\n",
    "# Decode a json response from Peltarion deployment API into a numpy array\n",
    "# The resulting array represents one or several samples\n",
    "def decode_api_response(response_json, output_param_name='output'):\n",
    "    res = []\n",
    "    for sample in response_json['rows']:\n",
    "        data_base64 = sample[output_param_name].split(',')[1]\n",
    "        data_numpy = decode_base64(data_base64)\n",
    "        res.append(data_numpy)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ' -- insert the URL you find on the Deployment view -- '\n",
    "token = ' -- insert the token you find on the Deployment view --'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input numpy array: (100, 10, 10, 3)\n",
      "Shape of the returned numpy array:  (100, 10, 10, 5)\n"
     ]
    }
   ],
   "source": [
    "features= np.load('/home/asa/projects/potkaista_dev/features.npy')\n",
    "print(\"Shape of the input numpy array:\", features.shape)\n",
    "api_data = prepare_api_data(features, input_param_name=\"features.npy_0\")\n",
    "preds = get_predictions(api_data, token, url)\n",
    "decoded = decode_api_response(preds, output_param_name=\"labels.npy_0\")\n",
    "print(\"Shape of the returned numpy array: \", decoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
